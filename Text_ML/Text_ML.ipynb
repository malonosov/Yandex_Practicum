{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6172684b",
   "metadata": {},
   "source": [
    "#                    Машинное обучение для текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8c357",
   "metadata": {},
   "source": [
    "####  <font color='red'>Описание :</font>\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "####  <font color='red'>Что надо сделать:</font>\n",
    "Обучить модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "####  <font color='red'>Цель:</font> \n",
    "Построить модель со значением метрики качества F1 не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a62a3c5",
   "metadata": {},
   "source": [
    "# 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffcff28",
   "metadata": {},
   "source": [
    "## 1.1. Загрузка и установка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd668047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (0.7.10)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859881a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (3.0.9)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.6.1-cp310-cp310-win_amd64.whl (12.0 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.12-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 989.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: thinc, spacy\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.0.17\n",
      "    Uninstalling thinc-8.0.17:\n",
      "      Successfully uninstalled thinc-8.0.17\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.0.9\n",
      "    Uninstalling spacy-3.0.9:\n",
      "      Successfully uninstalled spacy-3.0.9\n",
      "Successfully installed spacy-3.6.1 thinc-8.1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.6.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420e8c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "     ---------------------------------------- 13.7/13.7 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting spacy<3.1.0,>=3.0.0\n",
      "  Using cached spacy-3.0.9-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (5.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (22.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.23.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (65.6.3)\n",
      "Collecting thinc<8.1.0,>=8.0.3\n",
      "  Using cached thinc-8.0.17-cp310-cp310-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.1.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.28.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.64.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.6)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.1.1)\n",
      "Installing collected packages: thinc, spacy\n",
      "Successfully installed spacy-3.0.9 thinc-8.0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script spacy.exe is installed in 'C:\\Users\\Aleksey\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f18c99",
   "metadata": {},
   "source": [
    "## 1.2. Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6841bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#основное\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ea93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#предобработка\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c611bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#токенизация\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "898d5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#модели\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier, Pool, cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b394e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#обучение\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tune_sklearn import TuneGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "19a8cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#метрики\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50caa97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#разное\n",
    "plt.style.use('dark_background')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27296da",
   "metadata": {},
   "source": [
    "## 1.3. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f44b28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "debfca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a979f321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89f6ee38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1                1  D'aww! He matches this background colour I'm s...      0\n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4                4  You, sir, are my hero. Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537baf79",
   "metadata": {},
   "source": [
    "Первое, что мы видим - твитты на английском языке. Второе - они содержат много ненужных слов. Третье - датасет довольно большой. В связи с этим надо будет решить каким образом проводить его токенизацию, что это не заняло слишком много времени и ресурсов компьютера. Но сначала выполним предобработку твиттов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfe571c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95897ff0",
   "metadata": {},
   "source": [
    "Один класс преобладает над другим. Необходимо будет это учесть при обучении моеделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7014e8fd",
   "metadata": {},
   "source": [
    "## 1.4. Очитска текста приведение слов к стандартному виду"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a47fe",
   "metadata": {},
   "source": [
    "Приведем столбец к типу list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07756a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['text'] = list(df_raw['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ec414",
   "metadata": {},
   "source": [
    "Напишим функцию, удаляющую все кроме букв, цифр и пробелов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00934ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preprocess(text):\n",
    "    a = re.sub(r'[+\\W]', '', text) # удаляем все символы кроме букв, цифр, знаков подчеркивания и пробелов\n",
    "    b = re.findall(r'\\w+', text) # находим все слова в тексте\n",
    "    return ' '.join([x for x in b if x.isalnum()]) # склеиваем найденные слова с пробелом между ними"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cbee895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['text'] = df_raw['text'].apply(df_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60a8d486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>More I can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>And for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself That is a ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer Umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>And I really don t think you understand I came...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation Why the edits made under my userna...      0\n",
       "1                1  D aww He matches this background colour I m se...      0\n",
       "2                2  Hey man I m really not trying to edit war It s...      0\n",
       "3                3  More I can t make any real suggestions on impr...      0\n",
       "4                4  You sir are my hero Any chance you remember wh...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  And for the second time of asking when your vi...      0\n",
       "159288      159447  You should be ashamed of yourself That is a ho...      0\n",
       "159289      159448  Spitzer Umm theres no actual article for prost...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  And I really don t think you understand I came...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c27565",
   "metadata": {},
   "source": [
    "Исчезли знаки препинания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc76a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d501d66",
   "metadata": {},
   "source": [
    "## 1.5. Токенизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195827e1",
   "metadata": {},
   "source": [
    "Выполним токенизацию текста с помощью лемм. Посмотрим сколько времени это может занять. Поскольку твитты на английском языке для лемматизации будем использовать библиотеку spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b25f1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "894d99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b4ae8",
   "metadata": {},
   "source": [
    "Проверим как работает функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a30eb468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>More I can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>And for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself That is a ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer Umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>And I really don t think you understand I came...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation Why the edits made under my userna...      0\n",
       "1                1  D aww He matches this background colour I m se...      0\n",
       "2                2  Hey man I m really not trying to edit war It s...      0\n",
       "3                3  More I can t make any real suggestions on impr...      0\n",
       "4                4  You sir are my hero Any chance you remember wh...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  And for the second time of asking when your vi...      0\n",
       "159288      159447  You should be ashamed of yourself That is a ho...      0\n",
       "159289      159448  Spitzer Umm theres no actual article for prost...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  And I really don t think you understand I came...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f97b6da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 159292/159292 [06:33<00:00, 404.32it/s]\n"
     ]
    }
   ],
   "source": [
    "new_corpus = []\n",
    "\n",
    "for doc in tqdm(nlp.pipe(df_lem['text'], batch_size=64, n_process=-1, disable=[\"parser\", \"ner\"]), total=len(df_lem['text'])):\n",
    "    word_list = [tok.lemma_ for tok in doc]\n",
    "    new_corpus.append(' '.join(word_list))\n",
    "    \n",
    "df_lem['lemm_spacy_new'] = new_corpus  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f737a84f",
   "metadata": {},
   "source": [
    "Значительно быстрее. Далее посмотрим как это повлияет на определение тональности твиттов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf6c100f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_spacy_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour I m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man I m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>More I can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>And for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself That is a ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer Umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spitzer Umm there s no actual article for pros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>And I really don t think you understand I came...</td>\n",
       "      <td>0</td>\n",
       "      <td>and I really don t think you understand I come...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic  \\\n",
       "0                0  Explanation Why the edits made under my userna...      0   \n",
       "1                1  D aww He matches this background colour I m se...      0   \n",
       "2                2  Hey man I m really not trying to edit war It s...      0   \n",
       "3                3  More I can t make any real suggestions on impr...      0   \n",
       "4                4  You sir are my hero Any chance you remember wh...      0   \n",
       "...            ...                                                ...    ...   \n",
       "159287      159446  And for the second time of asking when your vi...      0   \n",
       "159288      159447  You should be ashamed of yourself That is a ho...      0   \n",
       "159289      159448  Spitzer Umm theres no actual article for prost...      0   \n",
       "159290      159449  And it looks like it was actually you who put ...      0   \n",
       "159291      159450  And I really don t think you understand I came...      0   \n",
       "\n",
       "                                           lemm_spacy_new  \n",
       "0       Explanation why the edit make under my usernam...  \n",
       "1       d aww he match this background colour I m seem...  \n",
       "2       hey man I m really not try to edit war it s ju...  \n",
       "3       More I can t make any real suggestion on impro...  \n",
       "4       you sir be my hero any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159287  and for the second time of ask when your view ...  \n",
       "159288  you should be ashamed of yourself that be a ho...  \n",
       "159289  Spitzer Umm there s no actual article for pros...  \n",
       "159290  and it look like it be actually you who put on...  \n",
       "159291  and I really don t think you understand I come...  \n",
       "\n",
       "[159292 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0657dd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aleksey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5c35b",
   "metadata": {},
   "source": [
    "## 1.6. Векторизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d35d8d4",
   "metadata": {},
   "source": [
    "Применим TfidfVectorizer с английским списком стоп слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e334fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083ac04",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65042188",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_lem, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb7d8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['lemm_spacy_new']\n",
    "y_train = train['toxic']\n",
    "X_test = test['lemm_spacy_new']\n",
    "y_test = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10418113",
   "metadata": {},
   "source": [
    "Обучим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da18e362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c1980b",
   "metadata": {},
   "source": [
    "Применим обученную модель для трансформации признаков обучающей и тестовой выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3abc0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76d4d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046158e9",
   "metadata": {},
   "source": [
    "# 2. Определение лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725437e7",
   "metadata": {},
   "source": [
    "### 2.1. Логистическая регрессия "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2d642",
   "metadata": {},
   "source": [
    "Применим кросс-валидацию и GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dec8467e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: range(1, 11, 2),\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: range(1, 11, 2),\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': range(1, 11, 2),\n",
       "                         'class_weight': [None, 'balanced']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = { 'C': range(1, 11, 2), 'class_weight': [None, 'balanced'] }\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "\n",
    "# инициализируем GridSearchCV\n",
    "cv_lr = GridSearchCV(estimator = model_lr, \n",
    "                           param_grid = param, \n",
    "                           cv = 3,\n",
    "                           n_jobs = -1, \n",
    "                           verbose = 0, \n",
    "                           scoring = 'f1',\n",
    "                          )\n",
    "cv_lr.fit(X_train_vec, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a58aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры модели:{'C': 9, 'class_weight': 'balanced'}\n",
      "Лучшая метрика f1 на кросс-валидации:0.7673059430220284\n"
     ]
    }
   ],
   "source": [
    "# Лучшие параметры и лучшая оценка модели\n",
    "best_params_lr = cv_lr.best_params_\n",
    "print(f'Лучшие параметры модели:{best_params_lr}')\n",
    "\n",
    "best_score_lr = cv_lr.best_score_\n",
    "print(f'Лучшая метрика f1 на кросс-валидации:{best_score_lr}')\n",
    "\n",
    "best_model_lg = cv_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc85f9",
   "metadata": {},
   "source": [
    "## 2.2. CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9584cbef",
   "metadata": {},
   "source": [
    "Применим кросс-валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b1f7024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.7355268638\n",
      "bestIteration = 997\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.7373639994\n",
      "bestIteration = 994\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.7413984462\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 0.4517345\ttotal: 925ms\tremaining: 15m 23s\n",
      "100:\tlearn: 0.6163509\ttotal: 1m 21s\tremaining: 12m 5s\n",
      "200:\tlearn: 0.6654965\ttotal: 2m 39s\tremaining: 10m 33s\n",
      "300:\tlearn: 0.6965276\ttotal: 3m 56s\tremaining: 9m 9s\n",
      "400:\tlearn: 0.7186754\ttotal: 5m 14s\tremaining: 7m 49s\n",
      "500:\tlearn: 0.7328367\ttotal: 6m 32s\tremaining: 6m 30s\n",
      "600:\tlearn: 0.7436928\ttotal: 7m 49s\tremaining: 5m 11s\n",
      "700:\tlearn: 0.7528965\ttotal: 9m 7s\tremaining: 3m 53s\n",
      "800:\tlearn: 0.7626091\ttotal: 10m 25s\tremaining: 2m 35s\n",
      "900:\tlearn: 0.7698626\ttotal: 11m 42s\tremaining: 1m 17s\n",
      "999:\tlearn: 0.7746248\ttotal: 12m 59s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x243f3413fa0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем Pool с данными\n",
    "train_data = Pool(data=X_train_vec, label=y_train)\n",
    "\n",
    "# Указываем параметры модели\n",
    "params = {\n",
    "    'eval_metric': 'F1',\n",
    "    'loss_function': 'Logloss',\n",
    "    'learning_rate': 0.05,\n",
    "    'random_seed': 2007,\n",
    "    'verbose': 100\n",
    "}\n",
    "\n",
    "# Проводим кросс-валидацию\n",
    "cv_data = cv(params=params,\n",
    "             pool=train_data,\n",
    "             fold_count=3,\n",
    "             shuffle=True,\n",
    "             partition_random_seed=0,\n",
    "             stratified=False,\n",
    "             verbose=False,\n",
    "             early_stopping_rounds=200)\n",
    "\n",
    "# Создаем модель CatBoostClassifier\n",
    "model_cb = CatBoostClassifier(**params)\n",
    "\n",
    "# Обучаем модель CatBoostClassifier\n",
    "model_cb.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52489851",
   "metadata": {},
   "source": [
    "Найдем best_score для CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3352bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_cb = cv_data['test-F1-mean'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ae7ef73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(best_score_cb,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f16324e",
   "metadata": {},
   "source": [
    "Как видно на кросс-валидации лучшее значение метрики F1 у логистической регрессии. Ее и возьмем для проверки на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8454b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание результатов для тестовой выборки\n",
    "predictions = best_model_lg.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ba70178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1 для модели CatBoostClassifier после лемматизации составило 0.763\n"
     ]
    }
   ],
   "source": [
    "print('Значение F1 для модели логистической регрессии составило', \\\n",
    "      round(f1_score(y_test, predictions),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849a8d4",
   "metadata": {},
   "source": [
    "## 3. KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791c1db",
   "metadata": {},
   "source": [
    "Для проверки корректности работы модели и экономии времени возьмем часть данных - 10% от общего количества твиттов. Хотя конечно для нейросетей чем больше обучающих данных, тем лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9958f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kr = df_raw.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8da342c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14307\n",
       "1     1622\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kr['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ad6aa",
   "metadata": {},
   "source": [
    "Соотношение целевых переменных сохранилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6271640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kr['text'] = list(df_kr['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1589391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kr['text'] = df_kr['text'].apply(df_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "291563c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15929/15929 [01:54<00:00, 138.58it/s]\n"
     ]
    }
   ],
   "source": [
    "new_corpus_kr = []\n",
    "\n",
    "for doc in tqdm(nlp.pipe(df_kr['text'], batch_size=64, n_process=-1, disable=[\"parser\", \"ner\"]), total=len(df_kr['text'])):\n",
    "    word_list = [tok.lemma_ for tok in doc]\n",
    "    new_corpus_kr.append(' '.join(word_list))\n",
    "    \n",
    "df_kr['lemm_spacy_new'] = new_corpus_kr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "360654c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (2.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dd5b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.56.2)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\aleksey\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\aleksey\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19698792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2828b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_kr, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a985c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['lemm_spacy_new']\n",
    "y_train = train['toxic']\n",
    "X_test = test['lemm_spacy_new']\n",
    "y_test = test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a8284448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание токенизатора\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "27c02a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение токенизатора\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c55e2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b972403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование текстов в последовательности чисел\n",
    "sequences = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "29d3e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполнение последовательностей до одинаковой длины\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "data = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4cdd3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание модели нейронной сети\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_length))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ca22c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка модели \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "115c0583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6372/6372 [==============================] - 1346s 211ms/step - loss: 0.2009 - accuracy: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21047d1ef20>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучение модели\n",
    "model.fit(data, y_train, epochs=1, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7d19dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bc921b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pad_sequences(new_sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6801c8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 89ms/step\n"
     ]
    }
   ],
   "source": [
    "# Предсказание результатов для тестовой выборки\n",
    "predictions = model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "51d25e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_kr = []\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        predictions_kr.append(1)\n",
    "    elif predictions[i] < 0.5:\n",
    "        predictions_kr.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c6ecacd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1 для модели Keras составило 0.743\n"
     ]
    }
   ],
   "source": [
    "print('Значение F1 для модели Keras составило', \\\n",
    "      round(f1_score(y_test, predictions_kr),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756020b0",
   "metadata": {},
   "source": [
    "## 4. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c9a3e",
   "metadata": {},
   "source": [
    "Лучший результат на кросс-валидации показала логистическая регрессия со значением F1 = 0.767. На втором месте оказался CatBoost со значением F1 = 0.738. На третьем - случайный лес с F1 = 0.65. Также следует отметить, что для ускорения процесса лусше использовать стемминг, а не лемматизацию. \n",
    "Для использования на тестовой выборке была выбрана модель логистической регрессии, которая показал значения F1 = 0.763."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
